{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85bf53c1-fa9f-4a70-a45a-ab72a995860a",
   "metadata": {},
   "source": [
    "# DESCRIPTION\n",
    "This notebook reads in the data and runs the \"month averaging\" linear regression for each grid cell. The notebook is designed to be executed with 10 processors as it decomposes the 2D domain in the x-dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb92f32-39b5-4dbb-9ac7-ede55d1c4c7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    IMPORT LIBRARIES\n",
    "\"\"\"\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import pyproj\n",
    "import rioxarray as rxr\n",
    "import datetime\n",
    "import pandas as pd\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0cae127a-fdb5-4aa3-9d45-bdd1d09a015c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    INPUTS\n",
    "\"\"\"\n",
    "## processor identification ##\n",
    "me = 0\n",
    "## total number of processors ##\n",
    "num_proc = 10 \n",
    "## output filepath ##\n",
    "fpath_out = '/glade/scratch/rossamower/snow/snowmodel/aso/california/tuolumne/snowmodel/cheyenne/outputs/aso_sm/ml_results/grid/take_2/'\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6345c92d-3893-4325-8349-bcf0fa6ada34",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "    LOAD DATASET\n",
    "\"\"\"\n",
    "ds_output_dir = '/glade/scratch/rossamower/snow/snowmodel/aso/california/tuolumne/snowmodel/cheyenne/outputs/aso_sm/'\n",
    "ds = xr.load_dataset(ds_output_dir + 'aso_sm_merge_clean_2.nc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c86ccd2f-111d-4ad6-abe3-12bdf52450ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(df,testyr,trainyr,isOneHot = True):\n",
    "    \"\"\"\n",
    "        FUNCTION TAKES IN DATA AND CREATES TEST AND TRAINING DATASET\n",
    "    \"\"\"\n",
    "    totyrs = trainyr + testyr\n",
    "    if isOneHot == True:\n",
    "        df_totyrs = df[df.date_year.isin(totyrs)]\n",
    "        if 2015 in testyr:\n",
    "            df3 = df_totyrs[df_totyrs.date_month != 2]\n",
    "            df3 = df3[df3.date_month != 7]\n",
    "        elif 2017 in testyr:\n",
    "            df3 = df_totyrs[df_totyrs.date_month != 2]\n",
    "            df3 = df3[df3.date_month != 1]\n",
    "            df3 = df3[df3.date_month != 8]\n",
    "            df3 = df3[df3.date_month != 4]\n",
    "        else:\n",
    "            df3 = df_totyrs[df_totyrs.date_month != 2]\n",
    "            df3 = df3[df3.date_month != 1]\n",
    "            df3 = df3[df3.date_month != 8]\n",
    "        df_hot1 = pd.get_dummies(data=df3, columns=['date_month'],drop_first = False)\n",
    "    else:\n",
    "        df_hot1 = df\n",
    "        \n",
    "    ## train/test ##\n",
    "    df_train = df_hot1[df_hot1.date_year.isin(trainyr)]\n",
    "    df_test = df_hot1[df_hot1.date_year.isin(testyr)]\n",
    "    ## drop na's ##\n",
    "    df_tn_nona = df_train.dropna(axis = 0, how = 'any')\n",
    "    df_ts_nona = df_test.dropna(axis = 0, how = 'any')\n",
    "    ## create index vector ##\n",
    "    index_ = df_ts_nona.index\n",
    "    ## pull out labels ##\n",
    "    y_train_ = df_tn_nona.aso_swe\n",
    "    y_test_ = df_ts_nona.aso_swe\n",
    "    ## drop columns ##\n",
    "    if isOneHot == True:\n",
    "        df_tn_nona_ = df_tn_nona.drop(columns = ['aso_swe','date_year'])\n",
    "        df_ts_nona_ = df_ts_nona.drop(columns = ['aso_swe','date_year'])\n",
    "    else:\n",
    "        df_tn_nona_ = df_tn_nona.drop(columns = ['aso_swe','date_year','date_month'])\n",
    "        df_ts_nona_ = df_ts_nona.drop(columns = ['aso_swe','date_year','date_month'])\n",
    "    \n",
    "    return df_tn_nona_,y_train_,df_ts_nona_,y_test_,index_,df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cd1d0b5e-93f2-4243-b1e0-27fc80458f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_stats(y,yhat,X):\n",
    "    \"\"\"\n",
    "        FUNCTION CALCULATES R2 AND ADJUSTED R2 VALUES\n",
    "    \"\"\"\n",
    "    SS_Residual = sum((y-yhat)**2)       \n",
    "    SS_Total = sum((y-np.mean(y))**2) \n",
    "    if SS_Total == 0.0:\n",
    "        r_squared = 0.0\n",
    "    else:\n",
    "        r_squared = 1 - (float(SS_Residual))/SS_Total\n",
    "    if len(y)-X.shape[1]-1 == 0:\n",
    "        adjusted_r_squared = -1.0\n",
    "    else:\n",
    "        adjusted_r_squared = 1 - (1-r_squared)*(len(y)-1)/(len(y)-X.shape[1]-1)\n",
    "    \n",
    "    return r_squared,adjusted_r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a655852-9bc9-4d95-b23a-569dee595cfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "def lr1(X,y):\n",
    "    \"\"\"\n",
    "        FIT LINEAR REGRESSION USING SKLEARN\n",
    "    \"\"\"\n",
    "    model = LinearRegression()\n",
    "    model.fit(X, y)\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "43bf48da-7198-4b7c-86e3-69ad7e982bda",
   "metadata": {},
   "outputs": [],
   "source": [
    "def log_inverse(arry):\n",
    "    \"\"\"\n",
    "        INVERSE LN + 1 TRANSFORMATION\n",
    "    \"\"\"\n",
    "    arry =  np.exp(arry) - 1\n",
    "    return arry"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "53be6c92-1afc-48a5-bb90-ebfaa26a279c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_lr(df,testyr,trainyr,isOneHot):\n",
    "    \"\"\"\n",
    "        FUNCTION GETS THE TRAINING AND TESTING DATA AND THEN PERFORMS LINEAR REGRESSION AND MODEL STATISTICS\n",
    "    \"\"\"\n",
    "    ## call function to get cleaned training and testing dataframes ##\n",
    "    x_train, y_train, x_test, y_test, index,df_test1 = preprocess(df,testyr,trainyr,isOneHot)\n",
    "    ## fit model ##\n",
    "    model = lr1(x_train,y_train)\n",
    "    ## predictions ##\n",
    "    baseline_yhat_tf = model.predict(x_test)\n",
    "    ## get stats ##\n",
    "    r_squared,adjusted_r_squared = reg_stats(y_test,baseline_yhat_tf,x_test)\n",
    "    ## model parameters ##\n",
    "    bias = model.intercept_\n",
    "    coef = model.coef_\n",
    "    yhat_bl = baseline_yhat_tf.flatten()\n",
    "    ## log inverse ##\n",
    "    yhat_bl = log_inverse(yhat_bl)\n",
    "    \n",
    "    return df_test1,index,yhat_bl,bias,coef,r_squared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ac96d420-da44-4b3f-91fe-1bca1a86aa3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_merge(pred,name,index,df_orig,lst):\n",
    "    \"\"\"\n",
    "        MERGE DATAFRAMES FROM THE CROSS-VALIDATION SAMPLE\n",
    "    \"\"\"\n",
    "    result = pd.DataFrame(data = {name:pred},\n",
    "                              index = index)\n",
    "    \n",
    "    df_1 = pd.merge(df_orig, result, \n",
    "                    left_index = True, right_index = True, \n",
    "                    how=\"left\", indicator=False)\n",
    "    \n",
    "    lst.append(df_1)\n",
    "    return lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce156362-9475-493f-9861-ecd210b917ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dataframe(X,y,date):\n",
    "    \"\"\"\n",
    "        FUNCTION CREATES DATAFRAME FOR GRID CELL\n",
    "    \"\"\"\n",
    "    ## initiate dataframe ##\n",
    "    df = pd.DataFrame({'date_t':date,\n",
    "            'sm_swe':X,\n",
    "            'aso_swe':y}) \n",
    "    ## create month/year variable ##\n",
    "    df['month_year'] = df['date_t'].dt.to_period('M')\n",
    "    ## groupby month/year variable ##\n",
    "    df_gp = pd.DataFrame(df.groupby('month_year')[['aso_swe','sm_swe']].mean())\n",
    "    ## reset index ##\n",
    "    df_gp = df_gp.reset_index()\n",
    "    ## create year and month column ##\n",
    "    df_gp['date_year'] = df_gp['month_year'].dt.year\n",
    "    df_gp['date_month'] = df_gp['month_year'].dt.month\n",
    "    ## drop month/year ##\n",
    "    df_gp = df_gp.drop(columns = ['month_year'])\n",
    "    \n",
    "    return df_gp\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0ce3b679-ed1d-448e-82b1-424a7842b67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_grid(ds,i,j,y_val):\n",
    "        \"\"\"\n",
    "            LOOPS OVER CROSS-VALIDATION TRAIN/TESTING SAMPLES AND PERFORMS LINEAR REGRESSION AT EACH GRID CELL\n",
    "        \"\"\"\n",
    "        ## pull out X and datetime values ##\n",
    "        x_val = np.log1p(ds.sm_swe[:,j,i].values,dtype=np.float128)\n",
    "        date_t = np.array(pd.to_datetime(ds.time[:].values))\n",
    "        date_month = np.array(pd.to_datetime(ds.time[:].values).month)\n",
    "        date_year = np.array(pd.to_datetime(ds.time[:].values).year)     \n",
    "        ## create initial dataframe with X,y and timing ##\n",
    "        df1 = create_dataframe(x_val,y_val,date_t)\n",
    "        ## break down of train and test years ##\n",
    "        yr_list = [[2015,2016],[2017,2018]]\n",
    "        yr_test = [2019,2020]\n",
    "        training_yrs = [2013,2014]\n",
    "        ## create lr statistic lists ##\n",
    "        bias_bl_lst = []\n",
    "        r2_bl_lst = []\n",
    "        df_lst_bl = []\n",
    "        ## start cross-validation loop ##\n",
    "        for yr in yr_list:\n",
    "            testing_yrs = yr\n",
    "            ## create dataframe for grid ##\n",
    "            isOneHot = False\n",
    "            df_test1,index,yhat_bl,bias_bl_tn,coef_bl_tn,r2_bl_tn = grid_lr(df1,testing_yrs,\n",
    "                                             training_yrs,isOneHot)\n",
    "            ## merge results to dataframe ##\n",
    "            df_lst_bl = data_merge(yhat_bl,'yhat_bl',index,df_test1,df_lst_bl)\n",
    "            ## append training variables ##\n",
    "            training_yrs.append(yr[0])\n",
    "            training_yrs.append(yr[1])\n",
    "            bias_bl_lst.append(bias_bl_tn)\n",
    "            r2_bl_lst.append(r2_bl_tn)\n",
    "        ## run last validation ##  \n",
    "        isOneHot = False\n",
    "        df_test1,index,yhat_bl,bias_bl_ts,coef_bl_ts,r2_bl_ts = grid_lr(df1,yr_test,\n",
    "                                         training_yrs,isOneHot)\n",
    "        ## merge results to dataframe ##\n",
    "        df_lst_bl = data_merge(yhat_bl,'yhat_bl',index,df_test1,df_lst_bl)\n",
    "        \n",
    "        ## append and clean results ##\n",
    "        bias_bl_lst.append(bias_bl_ts)\n",
    "        r2_bl_lst.append(r2_bl_ts)\n",
    "        df_2_bl = pd.concat(df_lst_bl)\n",
    "        df_3_bl = df_2_bl.fillna(-9999.0)\n",
    "        return bias_bl_lst,r2_bl_lst,list(coef_bl_ts),df_3_bl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "fb7d32a5-963c-449d-b5e9-3bc3e72b26d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def lst_to_output(lst,name,fpath,me,toFile=True):\n",
    "    \"\"\"\n",
    "        FUNCTION CONVERTS LISTS TO NUMPY ARRAYS, PERFORMS CLEANING, AND OUTPUTS TO .GDAT FILES\n",
    "    \"\"\"\n",
    "    arr = np.array(lst,dtype = np.float64)\n",
    "    arr[arr == -9999.0] = np.nan\n",
    "    if toFile == True:\n",
    "        arr.tofile(fpath + name +'_ln_'  + str(me) +'_.gdat')\n",
    "    return arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e273692f-e3bc-4c5e-95e0-5e5b2efcede0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 00:00:00.03\n",
      "END LINEAR REGRESSION ---------------->\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "    RUN MODEL\n",
    "\"\"\"\n",
    "from IPython.display import clear_output\n",
    "import time\n",
    "start = time.time()\n",
    "import sys \n",
    "\n",
    "## 1D-decomp identification ##\n",
    "\n",
    "if me == 0:\n",
    "    i_start = 0\n",
    "    i_end = i_start + 101\n",
    "elif me == num_proc:\n",
    "    i_start = (me * 100) + 1\n",
    "    i_end = i_start + 45\n",
    "else:\n",
    "    i_start = (me * 100) + 1\n",
    "    i_end = i_start + 100\n",
    "    \n",
    "## instantiate lists ##\n",
    "bl_lst = []\n",
    "sm_lst = []\n",
    "aso_lst = []\n",
    "bl_r2_lst = []\n",
    "bl_bias_lst = []\n",
    "bl_coef_lst = []\n",
    "\n",
    "\n",
    "## create pd datatime that is grouped by year and month to join data to ##\n",
    "date_pd = pd.DataFrame({'time':pd.to_datetime(ds.time[:].values)})#,\n",
    "date_pd['month_year'] = date_pd['time'].dt.to_period('M')\n",
    "date_pd['blank'] = 1\n",
    "df_new = pd.DataFrame(date_pd.groupby('month_year')['blank'].mean())\n",
    "df_new = df_new.reset_index()\n",
    "## start iteration ##\n",
    "for i in range(i_start,i_end):\n",
    "    print(i,end = ' ')\n",
    "    for j in range(ds.y.shape[0]):\n",
    "        ## condition for grid cells where aso data is NaN ##\n",
    "        if np.isnan(ds.notGrid[j,i].values) == True: # dont run model \n",
    "            yhat_bl = list(np.full((23), -9999.0))\n",
    "            sm_bl = list(np.full((23), -9999.0))\n",
    "            aso_bl = list(np.full((23), -9999.0))\n",
    "            r2_bl = list(np.full((3), -9999.0))\n",
    "            coef_bl = list(np.full((1), -9999.0))\n",
    "            bias_bl = list(np.full((3), -9999.0))\n",
    "            \n",
    "        else:\n",
    "            y_val = np.log1p(ds.aso_swe[:,j,i].values,dtype=np.float128)\n",
    "            try:\n",
    "                ## grid regression ##\n",
    "                bias_bl,r2_bl,coef_bl,df_bl = run_grid(ds,i,j,y_val)\n",
    "                ## grid merge and post-process ##\n",
    "                df_bl_j = df_new.join(df_bl,how = 'outer')\n",
    "                df_bl_j = df_bl_j[df_bl_j['sm_swe'].notna()]\n",
    "                df_bl_j = df_bl_j.fillna(-9999.0)\n",
    "                yhat_bl = df_bl_j['yhat_bl'].to_list() #yhat_oh\n",
    "                sm_bl = df_bl_j['sm_swe'].to_list() #yhat_oh\n",
    "                aso_bl = df_bl_j['aso_swe'].to_list() #yhat_oh\n",
    "\n",
    "\n",
    "            except:\n",
    "                yhat_bl = list(np.full((23), -9999.0))\n",
    "                r2_bl = list(np.full((3), -9999.0))\n",
    "                coef_bl = list(np.full((1), -9999.0))\n",
    "                bias_bl = list(np.full((3), -9999.0))\n",
    "                sm_bl = list(np.full((23), -9999.0))\n",
    "                aso_bl = list(np.full((23), -9999.0))\n",
    "\n",
    "        for val in range(0,len(yhat_bl)):\n",
    "            bl_lst.append(yhat_bl[val])\n",
    "            sm_lst.append(sm_bl[val])\n",
    "            aso_lst.append(aso_bl[val])\n",
    "            \n",
    "        for val in range(0,len(bias_bl)):\n",
    "            bl_bias_lst.append(bias_bl[val])\n",
    "            bl_r2_lst.append(r2_bl[val])\n",
    "            \n",
    "        for val in range(0,len(coef_bl)):\n",
    "            bl_coef_lst.append(coef_bl[val])\n",
    "\n",
    "                \n",
    "end = time.time()\n",
    "hours, rem = divmod(end-start, 3600)\n",
    "minutes, seconds = divmod(rem, 60)\n",
    "print(\"{:0>2}:{:0>2}:{:05.2f}\".format(int(hours),int(minutes),seconds))\n",
    "\n",
    "                \n",
    "## data output ##      \n",
    "bl_arr = lst_to_output(bl_lst,'bl_yhat',fpath_out,me,toFile=False) \n",
    "sm_arr = lst_to_output(sm_lst,'bl_sm',fpath_out,me,toFile=False) \n",
    "aso_arr = lst_to_output(aso_lst,'bl_aso',fpath_out,me,toFile=False) \n",
    "bl_r2_arr = lst_to_output(bl_r2_lst,'bl_r2',fpath_out,me,toFile=False)  \n",
    "bl_bias_arr = lst_to_output(bl_bias_lst,'bl_bias',fpath_out,me,toFile=False)  \n",
    "bl_coef_arr = lst_to_output(bl_coef_lst,'bl_coef',fpath_out,me,toFile=False)\n",
    " \n",
    "\n",
    "\n",
    "print('END LINEAR REGRESSION ---------------->')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ucb_w207",
   "language": "python",
   "name": "ucb_w207"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
